global:
  base_dir: qa_generation_input
  output_dir: qa_generation_output
  output_base_path: /var/kolo_data
  ollama_url: http://localhost:11434/api/generate

providers:
  question:
    provider: openai # Use "ollama" or "openai"
    model: gpt-4o-mini
  answer:
    provider: openai # Use "ollama" or "openai"
    model: gpt-4o-mini

prompts:
  question_prompt_header: >
    I want you to act as a data extractor for fine-tuning purposes. Then generate a comprehensive list of questions that capture all key facts, concepts, details, and nuances from the text. Your goal is to create questions that cover every important aspect of the content so that, when answered, the resulting QA pairs will fully represent the material for model fine-tuning. Ensure each question is clear, specific, and focused on one distinct key point. Analyze the following material:
  question_prompt_footer: |
    Please generate the following list:
    1. <question 1>
    2. <question 2>
    3. <question 3>
    etc.
  individual_question_prompt: 'File contents for : "{file_name}"'
  group_question_prompt: '{files_content}'
  answer_prompt: |
    {question}

file_groups:
  TrainTorchTune:
    iterations: 30
    files:
      - train_model_torchtune.ps1
      - merge_lora.py
      - convert_jsonl_to_json.py
  BuildImage:
    iterations: 30
    files:
      - build_image.ps1
      - dockerfile
      - supervisord.conf
  UninstallModel:
    iterations: 10
    files:
      - uninstall_model.ps1
  DeleteModel:
    iterations: 10
    files:
      - delete_model.ps1
  RunContainer:
    iterations: 10
    files:
      - create_and_run_container.ps1
      - run_container.ps1
  TrainUnsloth:
    iterations: 30
    files:
      - train_model_unsloth.ps1
      - train.py
  TrainingPSCommands:
    iterations: 30
    files:
      - train_model_torchtune.ps1
      - train_model_unsloth.ps1
  InstallModel:
    iterations: 10
    files:
      - install_model.ps1
  ListModels:
    iterations: 10
    files:
      - list_models.ps1
  CopyScripts:
    iterations: 10
    files:
      - copy_scripts.ps1
  CopyConfigs:
    iterations: 10
    files:
      - copy_configs.ps1
  ConnectSSH:
    iterations: 10
    files:
      - connect.ps1
  FineTuningGuide:
    iterations: 30
    files:
      - FineTuningGuide.md
  README:
    iterations: 30
    files:
      - README.md
  GenerateQAData:
    iterations: 30
    files:
      - generate_qa_data.ps1
      - generate_qa_data.py
      - generate_qa_config.yaml
  ConvertQAData:
    iterations: 15
    files:
      - parse_qa_data.py
      - convert_qa_output.ps1
  GenerateTrainingDataGuide:
    iterations: 30
    files:
      - GenerateTrainingDataGuide.md
  CopyQAInputGeneration:
    iterations: 10
    files:
      - copy_qa_input_generation.ps1
  GenerateQADataPy:
    iterations: 30
    files:
      - generate_qa_data.py
  GenerateQADataPs1:
    iterations: 10
    files:
      - generate_qa_data.ps1
  GenerateQADataYaml:
    iterations: 10
    files:
      - generate_qa_config.yaml
  DeleteQAGeneration:
    iterations: 10
    files:
      - delete_qa_generation_output.ps1
  CreateAndrunContainerAMD:
    iterations: 10
    files:
      - create_and_run_container_amd.ps1
  BuildImageAMD:
    iterations: 10
    files:
      - build_image_amd.ps1
  TrainModelTorchtuneAMDBoth:
    iterations: 10
    files:
      - train_model_torchtune_amd.ps1
      - train_model_torchtune.ps1
  TrainModelTorchtuneAMD:
    iterations: 5
    files:
      - train_model_torchtune_amd.ps1
  DockerFileAMD:
    iterations: 10
    files:
      - dockerfile-amd
      - dockerfile
