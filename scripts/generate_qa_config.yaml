global:
  base_dir: qa_generation_input
  output_dir: qa_generation_output
  output_base_path: /var/kolo_data
  ollama_url: http://localhost:11434/api/generate

providers:
  question:
    provider: openai # Use "ollama" or "openai"
    model: gpt-4o-mini
  answer:
    provider: openai # Use "ollama" or "openai"
    model: gpt-4o-mini

prompts:
  question_prompt_header: >
    Create a list of questions that thoroughly explore the functionality and workings of the following.
  question_prompt_footer: |
    Please generate the following list:
    1. <question 1>
    2. <question 2>
    3. <question 3>
    etc.
  individual_question_prompt: 'File contents for : "{file_name}"'
  group_question_prompt: '{files_content}'
  answer_prompt_header: ''

file_groups:
  TrainTorchTune:
    iterations: 15
    files:
      - train_model_torchtune.ps1
      - merge_lora.py
      - convert_jsonl_to_json.py
  BuildImage:
    iterations: 15
    files:
      - build_image.ps1
      - dockerfile
      - supervisord.conf
  UninstallModel:
    iterations: 5
    files:
      - uninstall_model.ps1
  DeleteModel:
    iterations: 5
    files:
      - delete_model.ps1
  RunContainer:
    iterations: 5
    files:
      - create_and_run_container.ps1
      - run_container.ps1
  TrainUnsloth:
    iterations: 15
    files:
      - train_model_unsloth.ps1
      - train.py
  TrainingPSCommands:
    iterations: 15
    files:
      - train_model_torchtune.ps1
      - train_model_unsloth.ps1
  InstallModel:
    iterations: 5
    files:
      - install_model.ps1
  ListModels:
    iterations: 5
    files:
      - list_models.ps1
  CopyScripts:
    iterations: 5
    files:
      - copy_scripts.ps1
  CopyConfigs:
    iterations: 5
    files:
      - copy_configs.ps1
  ConnectSSH:
    iterations: 5
    files:
      - connect.ps1
  FineTuningGuide:
    iterations: 15
    files:
      - FineTuningGuide.md
  README:
    iterations: 15
    files:
      - README.md
