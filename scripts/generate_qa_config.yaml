global:
  base_dir: qa_generation_input
  output_dir: qa_generation_output
  output_base_path: /var/kolo_data
  ollama_url: http://localhost:11434/api/generate

providers:
  question:
    provider: openai # Use "ollama" or "openai"
    model: gpt-4o-mini
  answer:
    provider: openai # Use "ollama" or "openai"
    model: gpt-4o-mini

QuestionInstructionList:
  - name: 'CasualandFormal'
    instruction:
      - 'For each question you generate write casually.'
      - 'For each question you generate write formally.'

AnswerInstructionList:
  - name: 'SimpleAndComplex'
    instruction:
      - 'For your answer keep it simple and short.'
      - 'For your answer give detail and reference any relevant content.'

GenerateQuestionLists:
  - name: 'DocumentList'
    questions:
      - 'Based on the above content, generate a list of questions where the user asks how to use different things.'
      - 'Based on the above content, generate a list of questions where the user asks to summarize different parts of the content.'
      - 'Based on the above content, generate a list of questions where the user wants to learn certain parts of the content.'
      - 'Based on the above content, generate a list of questions where the user wants to understand the concepts in the content.'
  - name: 'CodingList'
    questions:
      - 'Based on the above content, generate a list of questions where a new user wants to learn how to use the code and what it does using different tones and styles.'
      - 'Based on the above content, generate a list of questions where the user wants to know what a specific thing does in the code.'

FileHeaders:
  - name: 'DefaultFileHeader'
    description: 'The file contents for: {file_name}'

AnswerPrompt:
  - name: 'DefaultAnswerPrompt'
    description: |
      {file_content}
      {instruction}
      {question}

QuestionPrompt:
  - name: 'NoFileName'
    description: |
      {file_content}
      {instruction}
      {generate_question}
      Use the following output format:
        1. <question 1>
        2. <question 2>
        3. <question 3>
      etc.
  - name: 'WithFileName'
    description: |
      {file_content}
      {instruction}
      {generate_question}
      Use the following output format.
        1. <question 1>
        2. <question 2>
        3. <question 3>
      etc.
      You are required to reference {file_name_list} for every single question that you generate!

file_groups:
  UninstallModel:
    iterations: 3
    files:
      - uninstall_model.ps1
    question_prompt: WithFileName
    generate_question_list: [CodingList]
    question_instruction_list: [CasualandFormal]
    file_header: DefaultFileHeader
    answer_prompt: DefaultAnswerPrompt
    answer_instruction_list: [SimpleAndComplex]
  README:
    iterations: 3
    files:
      - README.md
    question_prompt: NoFileName
    generate_question_list: [DocumentList]
    question_instruction_list: [CasualandFormal]
    file_header: DefaultFileHeader
    answer_prompt: DefaultAnswerPrompt
    answer_instruction_list: [SimpleAndComplex]
  DeleteModel:
    iterations: 3
    files:
      - delete_model.ps1
    question_prompt: WithFileName
    generate_question_list: [CodingList]
    question_instruction_list: [CasualandFormal]
    file_header: DefaultFileHeader
    answer_prompt: DefaultAnswerPrompt
    answer_instruction_list: [SimpleAndComplex]
  BuildImage:
    iterations: 3
    question_prompt: WithFileName
    generate_question_list: [CodingList, DocumentList]
    question_instruction_list: [CasualandFormal]
    file_header: DefaultFileHeader
    answer_prompt: DefaultAnswerPrompt
    answer_instruction_list: [SimpleAndComplex]
    files:
      - build_image.ps1
      - dockerfile
      - supervisord.conf
  TrainTorchTune:
    iterations: 3
    question_prompt: WithFileName
    generate_question_list: [CodingList]
    question_instruction_list: [CasualandFormal]
    file_header: DefaultFileHeader
    answer_prompt: DefaultAnswerPrompt
    answer_instruction_list: [SimpleAndComplex]
    files:
      - train_model_torchtune.ps1
      - merge_lora.py
      - convert_jsonl_to_json.py
  TrainUnsloth:
    iterations: 3
    question_prompt: WithFileName
    generate_question_list: [CodingList]
    question_instruction_list: [CasualandFormal]
    file_header: DefaultFileHeader
    answer_prompt: DefaultAnswerPrompt
    answer_instruction_list: [SimpleAndComplex]
    files:
      - train_model_unsloth.ps1
      - train.py
  InstallModel:
    iterations: 3
    question_prompt: WithFileName
    generate_question_list: [CodingList]
    question_instruction_list: [CasualandFormal]
    file_header: DefaultFileHeader
    answer_prompt: DefaultAnswerPrompt
    answer_instruction_list: [SimpleAndComplex]
    files:
      - install_model.ps1
  ListModels:
    iterations: 3
    question_prompt: WithFileName
    generate_question_list: [CodingList]
    question_instruction_list: [CasualandFormal]
    file_header: DefaultFileHeader
    answer_prompt: DefaultAnswerPrompt
    answer_instruction_list: [SimpleAndComplex]
    files:
      - list_models.ps1
  FineTuningGuide:
    iterations: 3
    question_prompt: NoFileName
    generate_question_list: [DocumentList]
    question_instruction_list: [CasualandFormal]
    file_header: DefaultFileHeader
    answer_prompt: DefaultAnswerPrompt
    answer_instruction_list: [SimpleAndComplex]
    files:
      - FineTuningGuide.md
  GenerateTrainingDataGuide:
    iterations: 3
    question_prompt: NoFileName
    generate_question_list: [DocumentList]
    question_instruction_list: [CasualandFormal]
    file_header: DefaultFileHeader
    answer_prompt: DefaultAnswerPrompt
    answer_instruction_list: [SimpleAndComplex]
    files:
      - GenerateTrainingDataGuide.md
